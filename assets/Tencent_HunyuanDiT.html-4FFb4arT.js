import{_ as n}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as e,o as a,a as s}from"./app-BEhkVDlh.js";const i={},t=s(`<p>它是一种文本到图像的扩散转换器，强大的多分辨率扩散变压器，与其他开源模型相比，Hunyuan-DiT 在中文到图像生成方面树立了新的最先进水平。</p><p>通过查阅相关文档能够发现它其实就是基于 Stable Diffusion 实现的，它的增强点在于</p><ol><li>结合了预先训练的双语（英语和中文）CLIP 和多语言 T5 编码器</li><li>执行多轮对话和图像生成的能力，训练 MLLM 来理解多轮用户对话并输出用于图像生成的新文本提示</li></ol><h2 id="体验" tabindex="-1"><a class="header-anchor" href="#体验"><span>体验</span></a></h2><p><a href="https://hunyuan.tencent.com/bot/chat" target="_blank" rel="noopener noreferrer">https://hunyuan.tencent.com/bot/chat</a></p><h2 id="配置要求" tabindex="-1"><a class="header-anchor" href="#配置要求"><span>配置要求</span></a></h2><ul><li>需要支持 CUDA 的 NVIDIA GPU。 <ul><li>我们测试了 V100 和 A100 GPU。</li><li>最低：所需的最低 GPU 内存为 11GB。</li><li>推荐：我们建议使用具有 32GB 内存的 GPU，以获得更好的生成质量。</li></ul></li><li>测试操作系统：Linux</li></ul><h2 id="依赖与安装" tabindex="-1"><a class="header-anchor" href="#依赖与安装"><span>依赖与安装</span></a></h2><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token function">git</span> clone https://github.com/tencent/HunyuanDiT
<span class="token builtin class-name">cd</span> HunyuanDiT
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>提供了一个environment.yml用于设置 Conda 环境的文件</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 1. Prepare conda environment</span>
conda <span class="token function">env</span> create <span class="token parameter variable">-f</span> environment.yml

<span class="token comment"># 2. Activate the environment</span>
conda activate HunyuanDiT

<span class="token comment"># 3. Install pip dependencies</span>
python <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token parameter variable">-r</span> requirements.txt

<span class="token comment"># 4. (Optional) Install flash attention v2 for acceleration (requires CUDA 11.6 or above)</span>
python <span class="token parameter variable">-m</span> pip <span class="token function">install</span> git+https://github.com/Dao-AILab/flash-attention.git@v2.1.2.post3
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="模型下载" tabindex="-1"><a class="header-anchor" href="#模型下载"><span>模型下载</span></a></h2><p>要下载模型，请首先安装huggingface-cli。</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code>python <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token string">&quot;huggingface_hub[cli]&quot;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>然后使用以下命令下载模型：</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># 创建 &#39;ckpts&#39; 文件夹 用来保存模型</span>
<span class="token function">mkdir</span> ckpts
<span class="token comment"># 使用 huggingface-cli 命令下载模型.</span>
huggingface-cli download Tencent-Hunyuan/HunyuanDiT --local-dir ./ckpts
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>注意：如果No such file or directory: &#39;ckpts/.huggingface/.gitignore.lock&#39;在下载过程中出现类似错误，可以忽略该错误并通过执行重试该命令huggingface-cli download Tencent-Hunyuan/HunyuanDiT --local-dir ./ckpts</p></blockquote><h2 id="开始" tabindex="-1"><a class="header-anchor" href="#开始"><span>开始</span></a></h2><h3 id="使用gradio" tabindex="-1"><a class="header-anchor" href="#使用gradio"><span>使用Gradio</span></a></h3><p>在运行以下命令之前，请确保您已激活 conda 环境。</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># By default, we start a Chinese UI.</span>
python app/hydit_app.py

<span class="token comment"># Using Flash Attention for acceleration.</span>
python app/hydit_app.py --infer-mode fa

<span class="token comment"># You can disable the enhancement model if the GPU memory is insufficient.</span>
<span class="token comment"># The enhancement will be unavailable until you restart the app without the \`--no-enhance\` flag. </span>
python app/hydit_app.py --no-enhance

<span class="token comment"># Start with English UI</span>
python app/hydit_app.py <span class="token parameter variable">--lang</span> en
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="使用命令行" tabindex="-1"><a class="header-anchor" href="#使用命令行"><span>使用命令行</span></a></h3><p>三者模式启动</p><div class="language-bash line-numbers-mode" data-ext="sh" data-title="sh"><pre class="language-bash"><code><span class="token comment"># Prompt Enhancement + Text-to-Image. Torch mode</span>
python sample_t2i.py <span class="token parameter variable">--prompt</span> <span class="token string">&quot;渔舟唱晚&quot;</span>

<span class="token comment"># Only Text-to-Image. Torch mode</span>
python sample_t2i.py <span class="token parameter variable">--prompt</span> <span class="token string">&quot;渔舟唱晚&quot;</span> --no-enhance

<span class="token comment"># Only Text-to-Image. Flash Attention mode</span>
python sample_t2i.py --infer-mode fa <span class="token parameter variable">--prompt</span> <span class="token string">&quot;渔舟唱晚&quot;</span>

<span class="token comment"># Generate an image with other image sizes.</span>
python sample_t2i.py <span class="token parameter variable">--prompt</span> <span class="token string">&quot;渔舟唱晚&quot;</span> --image-size <span class="token number">1280</span> <span class="token number">768</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>更多的配置项</p><p>我们列出了一些更有用的配置以方便使用：</p><p>--prompt 图像生成的文字提示 --image-size 生成图像的大小 --seed 用于生成图像的随机种子 --infer-steps 采样步数 --negative 图像生成的负面提示 --infer-mode 推理模式（torch 或 fa） --sampler 扩散采样器（ddpm、ddim 或 dpmms） --no-enhance 禁用提示增强模型 --model-root 模型检查点的根目录 --load-key 加载学生模型或EMA模型（ema或模块）</p>`,27),l=[t];function c(o,r){return a(),e("div",null,l)}const m=n(i,[["render",c],["__file","Tencent_HunyuanDiT.html.vue"]]),u=JSON.parse('{"path":"/article/ai/Tencent_HunyuanDiT.html","title":"腾讯混元-HunyuanDiT","lang":"zh-CN","frontmatter":{"title":"腾讯混元-HunyuanDiT","date":"2024-05-15T00:00:00.000Z","categories":["AI绘画"],"tags":["腾讯"],"description":"它是一种文本到图像的扩散转换器，强大的多分辨率扩散变压器，与其他开源模型相比，Hunyuan-DiT 在中文到图像生成方面树立了新的最先进水平。 通过查阅相关文档能够发现它其实就是基于 Stable Diffusion 实现的，它的增强点在于 结合了预先训练的双语（英语和中文）CLIP 和多语言 T5 编码器 执行多轮对话和图像生成的能力，训练 MLL...","head":[["meta",{"property":"og:url","content":"https://lianyp.fun/lyp-blog/article/ai/Tencent_HunyuanDiT.html"}],["meta",{"property":"og:site_name","content":"小道空间-Vuepress开源轻博客系统"}],["meta",{"property":"og:title","content":"腾讯混元-HunyuanDiT"}],["meta",{"property":"og:description","content":"它是一种文本到图像的扩散转换器，强大的多分辨率扩散变压器，与其他开源模型相比，Hunyuan-DiT 在中文到图像生成方面树立了新的最先进水平。 通过查阅相关文档能够发现它其实就是基于 Stable Diffusion 实现的，它的增强点在于 结合了预先训练的双语（英语和中文）CLIP 和多语言 T5 编码器 执行多轮对话和图像生成的能力，训练 MLL..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-05-20T09:04:18.000Z"}],["meta",{"property":"article:author","content":"梁小道"}],["meta",{"property":"article:tag","content":"腾讯"}],["meta",{"property":"article:published_time","content":"2024-05-15T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-05-20T09:04:18.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"腾讯混元-HunyuanDiT\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-05-15T00:00:00.000Z\\",\\"dateModified\\":\\"2024-05-20T09:04:18.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"梁小道\\",\\"url\\":\\"https://lianyp.fun\\"}]}"]]},"headers":[{"level":2,"title":"体验","slug":"体验","link":"#体验","children":[]},{"level":2,"title":"配置要求","slug":"配置要求","link":"#配置要求","children":[]},{"level":2,"title":"依赖与安装","slug":"依赖与安装","link":"#依赖与安装","children":[]},{"level":2,"title":"模型下载","slug":"模型下载","link":"#模型下载","children":[]},{"level":2,"title":"开始","slug":"开始","link":"#开始","children":[{"level":3,"title":"使用Gradio","slug":"使用gradio","link":"#使用gradio","children":[]},{"level":3,"title":"使用命令行","slug":"使用命令行","link":"#使用命令行","children":[]}]}],"git":{"createdTime":1716002958000,"updatedTime":1716195858000,"contributors":[{"name":"liangyp","email":"2267841523@qq.com","commits":2}]},"readingTime":{"minutes":2.4,"words":721},"filePathRelative":"article/ai/Tencent_HunyuanDiT.md","localizedDate":"2024年5月15日","excerpt":"<p>它是一种文本到图像的扩散转换器，强大的多分辨率扩散变压器，与其他开源模型相比，Hunyuan-DiT 在中文到图像生成方面树立了新的最先进水平。</p>\\n<p>通过查阅相关文档能够发现它其实就是基于 Stable Diffusion 实现的，它的增强点在于</p>\\n<ol>\\n<li>结合了预先训练的双语（英语和中文）CLIP 和多语言 T5 编码器</li>\\n<li>执行多轮对话和图像生成的能力，训练 MLLM 来理解多轮用户对话并输出用于图像生成的新文本提示</li>\\n</ol>\\n<h2>体验</h2>\\n<p><a href=\\"https://hunyuan.tencent.com/bot/chat\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">https://hunyuan.tencent.com/bot/chat</a></p>","autoDesc":true}');export{m as comp,u as data};
